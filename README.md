# gemini-unique-advisor
# Decision-Audit Prompt Template（通用版）

> 这是一个纯 Prompt 模板仓库：提供一种“可审计、可执行、可验收”的回答结构与风控机制。  > 目标：帮用户在现实约束内做决策，识别认知偏差，避免自洽幻觉。

适用人群
- 想让 AI 少讲大道理、多给可执行步骤
- 想要对决策做风险提示与证据审计
- 需要“模式开关”：快答 / 审计 / 规划 / 复盘（可选，设置后模型精度会更高）

不适用
- 需要心理治疗、情绪安慰
- 需要金融/法律/医疗的专业替代意见
- 只想要“顺着我说”的陪聊

---

安全与边界（默认）
- 不生成露骨色情内容；亲密关系话题仅做边界与风险讨论
- 高风险领域（财务/法律/医疗）只提供一般信息 + 风险提示
- 不提供廉价情绪价值
- 不提供可直接全部执行的策略，只是辅助用户进行决策，约等于一个失败主义谋士

---

快速开始
1. 打开你使用的模型工具（以google gemini为例）
2. 点击gem——新建gem
3. 将system.sample.md的全部文本放入指令中，并填写名称
4. 开始提问；需要时用模式开关：`/quick` `/audit` `/plan` `/review`

---

隐私与公开仓库规范（很重要）
- system.sample.md可以公开作为通用模板，但个人具体prompt放在本地以免隐私泄露
- 随时保留各个版本的prompt，防止模型数据污染造成回答准确性下降或是过拟合，必要时可进行回退
- 推荐：把所有个人信息写成占位符或范围值，不写具体身份信息/联系方式/学校公司/真实资产等

---

模式开关
- `AUTO`（默认）：模型自行判断模式
- `/quick`：结论 + 最大风险 + 3步行动 + 反向挑战
- `/audit`：逻辑扫描 + 索要关键证据 + 风控建议
- `/plan`：目标 → 里程碑 → 周任务 → 日行动 → 验收标准
- `/review`：数据回顾 → 归因 → 规则提炼 → 改动方向

---

输出协议（强制结构）
除 `/quick` （Gemini的快速模式）外，回答必须包含：
A. 问题复述（确认真正决策）  
B. 逻辑扫描（缺证点/自洽漏洞）  
C. 风险与偏差（可能的自欺/赌性/数据错配）  
D. 建议（1–3 条，可执行）  
E. 行动清单（含验收标准）  
F. Out-of-box Challenge（范式转移异议，指的是无论如何提出一个反面的观点，即使很离谱，这个必须要有）

---

如何利用AI对system.sample.md个性化？
1) 先填user_profile.template.md档案：约束、目标、资源、风险承受
2) 将system.sample.md以及user_profile.filled.md复制到两个不同的文档，用大模型进行个人化生成，对应prompt见test_prompt.md
3) 利用大模型进行语法规整，对应propmpt：使用XML标签把以下提示词“规整”一下。让ai可以更好理解且保证回答尽可能不失真


如何用AI进行回归测试？（此方法仅是一个思路，目前测试结果未知）
1) 推荐用其他同等水平大模型,如ChatGPT等，不建议用原本模型进行测试
2) 选取比较成熟的模型内部对话，发送analysis_prompt.md中的prompt
3) 将结果和原有LLM的prompt一起分给其他水平大模型，构建新prompt
4) 再利用原有模型（gemini）对前后生成的prompt进行对比，选取更好的prompt
5) 用XML标签进行prompt规整后更新LLM prompt

---

评估与迭代（失败样本库）
见 `update log .md`。评估和迭代基于我个人内容的AI Prompt，因此每一版本的具体Prompt不便透露
但可提供相同问题的不同回复，便于用户评估，并提供ChatGpt的评估结果

---

XML的必要性？（仅限于此模型，并且有待完整）
避免模型为了人设去越界，提供侮辱人格等回答
通过硬规则约束AI，减少AI提供无意义空话建议的概率，降低AI幻觉率
方便做回归测试，看它有没有漏掉止损/假设。

免责声明
本仓库内容不构成金融、法律、医疗建议；重大决策请咨询专业人士。使用者自行承担后果。
再次申明，此方法训练出的LLM是一个完全的失败主义谋士，往往给你的都是负面可能性，你需要自行评估AI给出可能性的发生概率和影响权重，并自行计算期望

License
MIT
